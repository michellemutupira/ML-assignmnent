{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2iLYCRpPEKz",
    "outputId": "f19dce9a-a0e1-4651-c8f2-f633a016ac8d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2     # for capturing videos\n",
    "\n",
    "import shutil\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "import warnings\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "%matplotlib inline\n",
    "\n",
    "videoFile = '/content/drive/MyDrive/tonick/vid_cars.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pHl8zTsFDAW"
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxAQp0kiTGpY",
    "outputId": "eb69762a-a160-404f-f4b7-16b23a46a6ad"
   },
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WCPytAAqSzpb"
   },
   "outputs": [],
   "source": [
    "def identify_frames(img_path):    \n",
    "  img = image.load_img(img_path, color_mode='rgb', target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  features = model.predict(x)\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eid9vXsBEiMO"
   },
   "source": [
    "# Video Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMxlnbCKEsCV"
   },
   "source": [
    "## Frame Exctracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1Cq966uVEw0g"
   },
   "outputs": [],
   "source": [
    "def extract_frames(vid_path):\n",
    "    # set video file path of input video with name and extension\n",
    "    vid = cv2.VideoCapture(vid_path)\n",
    "\n",
    "\n",
    "    if not os.path.exists('images'):\n",
    "        os.makedirs('images')\n",
    "    else:\n",
    "        shutil.rmtree('images')\n",
    "        os.makedirs('images')\n",
    "    #identify frame\n",
    "    index = 0\n",
    "    while(True):\n",
    "        \n",
    "\n",
    "        # Extract images\n",
    "        ret, frame = vid.read()\n",
    "        # end of frames\n",
    "        if not ret: \n",
    "            break\n",
    "        # Saves images\n",
    "        name = 'frame' + str(index) + '.jpg'\n",
    "        print ('Creating... ' + name)\n",
    "        cv2.imwrite(name, frame)\n",
    "\n",
    "        # next frame\n",
    "        index += 1\n",
    "    vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "i5y9vtrPJxlH"
   },
   "outputs": [],
   "source": [
    "# extract_frames(videoFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2uGjXaCE1Vl"
   },
   "source": [
    "## Frame Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VAul90zBE46s"
   },
   "outputs": [],
   "source": [
    "def label_frames(inputpath, outputpath, videoFile):\n",
    "\n",
    "    if not os.path.exists('encoded_images'):\n",
    "        os.makedirs('encoded_images')\n",
    "    else:\n",
    "        shutil.rmtree('encoded_images')\n",
    "        os.makedirs('encoded_images')\n",
    "\n",
    "    count = 0\n",
    "    cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    font_scale = 3\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    obj_detected = []\n",
    "\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        filename =inputpath+\"/frame\"+str(count)+\".jpg\"\n",
    "        p = decode_predictions(identify_frames(filename))\n",
    "        label = p[0][0][1]\n",
    "        if label not in obj_detected:\n",
    "            obj_detected.append(label)\n",
    "        cv2.putText(frame, \"[*Object Detected] : \"+str(label), (25, 60), font, fontScale=font_scale,color=(0,255,0), thickness=3)\n",
    "        cv2.imwrite(outputpath+ str(label) + \" \" + str(count)+\".jpg\", frame)\n",
    "        print ('Econded... ' + str(label) + \"... \" + str(count))\n",
    "        count += 1\n",
    "    cap.release()\n",
    "    print (\"[**Frame Encoding] - Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gj4jdtiiE849"
   },
   "source": [
    "## Video Regeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UCXObSBkFAOU"
   },
   "outputs": [],
   "source": [
    "def build_video(inputpath,outputpath,fps):\n",
    "    if not os.path.exists('videos'):\n",
    "        os.makedirs('videos')\n",
    "    else:\n",
    "        shutil.rmtree('videos')\n",
    "        os.makedirs('videos')\n",
    "\n",
    "    image_array = []\n",
    "    files = [f for f in os.listdir(inputpath) if os.path.isfile(os.path.join(inputpath, f))]\n",
    "    files.sort(key = lambda x: int(x.split()[1][:-4]))\n",
    "    for i in range(len(files)):\n",
    "        img = cv2.imread(inputpath + files[i])\n",
    "        size =  (img.shape[1],img.shape[0])\n",
    "        img = cv2.resize(img,size)\n",
    "        image_array.append(img)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "    out = cv2.VideoWriter(outputpath,fourcc, fps, size)\n",
    "    for i in range(len(image_array)):\n",
    "        out.write(image_array[i])\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgWkY_YZIkvJ"
   },
   "source": [
    "# Get Objects Detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jT-Ru-ZcItTZ"
   },
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(\"./encoded_images\") if os.path.isfile(os.path.join(\"./encoded_images\", f))]\n",
    "fi = [i.split()[0] for i in files] \n",
    "detected_obj = list(set(fi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QwP-F9buu3R"
   },
   "source": [
    "# Main Menu Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2Cgz7XEu3Gx"
   },
   "source": [
    "## User Input Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq8bYed-MGNe",
    "outputId": "444ccb38-4bbb-4902-b48d-9a615b4921ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing user.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile user.py\n",
    "import streamlit as st\n",
    "import tempfile\n",
    "from base import *\n",
    "from model import *\n",
    "from video import *\n",
    "\n",
    "def filter_frame(txt_search):\n",
    "    files = [f for f in os.listdir(\"./encoded_images\") if os.path.isfile(os.path.join(\"./encoded_images\", f))]\n",
    "    files.sort(key = lambda x: int(x.split()[1][:-4]))\n",
    "    indices = [i for i, s in enumerate(files) if txt_search.lower() in s]\n",
    "    return files[indices[0]]\n",
    "\n",
    "files = [f for f in os.listdir(\"./encoded_images\") if os.path.isfile(os.path.join(\"./encoded_images\", f))]\n",
    "fi = [i.split()[0] for i in files] \n",
    "detected_obj = list(set(fi))\n",
    "\n",
    "def app():\n",
    "\n",
    "    global rez\n",
    "\n",
    "    rez = \"...\"\n",
    "\n",
    "\n",
    "    f = st.file_uploader(\"Upload video\")\n",
    "\n",
    "    s1, s2, s3 = st.beta_columns([1,4,2])\n",
    "\n",
    "    with s2:\n",
    "        search = st.text_input(\"Search for objects in video\")\n",
    "        if search in detected_obj:\n",
    "            rez = \"Found\"\n",
    "        else:\n",
    "            rez = \"Not Found\"\n",
    "        \n",
    "    with s3:\n",
    "        st.write('Search results')\n",
    "        if f is None:\n",
    "            status = st.write(f'{search} ...')\n",
    "        else:\n",
    "            status = st.write(f'{search} {rez}')\n",
    "\n",
    "\n",
    "    with st.beta_container():\n",
    "\n",
    "        col1, col2 = st.beta_columns([2,6])\n",
    "\n",
    "        with col1:\n",
    "            st.write(\"Objects in video\")\n",
    "            for i in range(len(detected_obj)):\n",
    "                st.write(str(i+1) +  \" \"+str(detected_obj[i]))\n",
    "        with col2:\n",
    "\n",
    "            if f is not None:\n",
    "                tfile = tempfile.NamedTemporaryFile(delete=False) \n",
    "                tfile.write(f.read())\n",
    "\n",
    "                with st.spinner('[*Extracting Frames] - Process Initialized...'):\n",
    "                    extract_frames(tfile.name, \"./images\")\n",
    "                st.success('[*Extracting Frames] - Process Completed...')\n",
    "\n",
    "                with st.spinner('[**Encoding Frames] - Process Initialized...'):\n",
    "                    label_frames(inputpath=\"./images\", outputpath='./encoded_images/', videoFile=r\"C:\\Users\\Blessed\\Videos\\vid_cars.mp4\")\n",
    "                st.success('[*Encoding Frames] - Process Completed...')\n",
    "\n",
    "                with st.spinner('[***Building Frames] - Process Initialized...'):\n",
    "                    build_video(inputpath='./encoded_images/', outputpath='./videos/video.mp4',fps=5)\n",
    "                st.success('[*Building Frames] - Process Completed...')\n",
    "\n",
    "                if search.lower() in detected_obj:\n",
    "                    rez = \"found\"\n",
    "                    img = Image.open('./encoded_images/'+str(filter_frame(search)))\n",
    "                    st.image(img, caption=search.lower() + \" frame found\")\n",
    "                else:\n",
    "                    play_video('./videos/video.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yf3rZYdyu8u2"
   },
   "source": [
    "## Home Dashboard with Preloaded Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ygk5-QouvCYR",
    "outputId": "5f64b96e-c761-4114-a36e-6f158d8d6e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing home.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile home.py\n",
    "import streamlit as st\n",
    "from base import *\n",
    "\n",
    "files = [f for f in os.listdir(\"./en_images\") if os.path.isfile(os.path.join(\"./en_images\", f))]\n",
    "fi = [i.split()[0] for i in files] \n",
    "detected_obj = list(set(fi))\n",
    "\n",
    "def filter_frame(txt_search):\n",
    "    files = [f for f in os.listdir(\"./en_images\") if os.path.isfile(os.path.join(\"./en_images\", f))]\n",
    "    files.sort(key = lambda x: int(x.split()[1][:-4]))\n",
    "    indices = [i for i, s in enumerate(files) if txt_search.lower() in s]\n",
    "    return files[indices[0]]\n",
    "\n",
    "def app():\n",
    "    global h_rez\n",
    "\n",
    "    h_rez = \"...\"\n",
    "\n",
    "    st.title('Object(s) Detection in video')\n",
    "\n",
    "    hs1, hs2, hs3 = st.beta_columns([1,4,2])\n",
    "\n",
    "    with hs2:\n",
    "        h_search = st.text_input(\"Search for objects in video\")\n",
    "        if h_search.lower() in detected_obj:\n",
    "            h_rez = \"found\"\n",
    "        else:\n",
    "            h_rez = \"not found\"\n",
    "        \n",
    "    with hs3:\n",
    "        st.write('Search results')\n",
    "        if h_search.lower() is None:\n",
    "            status = st.write(f'{h_search} ...')\n",
    "        else:\n",
    "            status = st.write(f'{h_search} {h_rez}')\n",
    "\n",
    "\n",
    "    if len(detected_obj) > 6:\n",
    "        col1, col2, col3 = st.beta_columns([2,2,6])\n",
    "        with col1:\n",
    "            st.subheader(\"Objects in video\")\n",
    "            for i in range(0,7):\n",
    "                st.write(str(i+1) +  \" \"+str(detected_obj[i]))\n",
    "        with col2:\n",
    "            st.write(\"\")\n",
    "            st.write(\"\")\n",
    "            st.write(\"\")\n",
    "            st.write(\"\")\n",
    "            for i in range(7,len(detected_obj)-1):\n",
    "                st.write(str(i+1) +  \" \"+str(detected_obj[i]))\n",
    "        with col3:\n",
    "            st.write(\"\")\n",
    "            st.write(\"\")\n",
    "            st.write(\"\")\n",
    "            st.write(\"\")\n",
    "            if h_search.lower() in detected_obj:\n",
    "                h_rez = \"found\"\n",
    "                img = Image.open('./en_images/'+str(filter_frame(h_search)))\n",
    "                st.image(img, caption=h_search.lower() + \" frame found\")\n",
    "            else:\n",
    "                play_video(\"video.mp4\")\n",
    "    else:\n",
    "        col1, col2 = st,beta_columns([2,6])\n",
    "        with col1:  \n",
    "            st.write(\"Objects in video\")\n",
    "            for i in range(len(detected_obj)):\n",
    "                st.write(str(i+1) +  \" \"+str(detected_obj[i]))\n",
    "        with col2:\n",
    "            play_video(\"video.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AInWyrLlvK1i"
   },
   "source": [
    "## About Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPuEhjFsvH1S",
    "outputId": "ee6ef7fc-451b-4361-fdf4-98e86c574a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing about.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile about.py\n",
    "import streamlit as st\n",
    "\n",
    "def app():\n",
    "    \n",
    "    st.title('Object Detection using VGG16 Model...')\n",
    "\n",
    "    c1, c2, c3 = st.beta_columns([4,2,4])\n",
    "    with c2:\n",
    "        st.write('Done by:')\n",
    "\n",
    "    b1,m1,l1 = st.beta_columns([3,1,3])\n",
    "    with b1:\n",
    "        st.write('Blessed Mutengwa - R182565F')\n",
    "        st.write('blessedmutengwa@gmail.com')\n",
    "    with m1:\n",
    "        st.write(\"|\")\n",
    "    with l1:\n",
    "        st.write('Linval Chisoko - R182565F')\n",
    "        st.write('linvaltchisoko@gmail.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpP2Le2sv1gD"
   },
   "source": [
    "## Base File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gls51R-jv4aW",
    "outputId": "cce7a6cb-2205-4eb0-abbf-69aac92b8167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing base.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile base.py\n",
    "import streamlit as st\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def play_video(vid_path):\n",
    "    try:\n",
    "        video_file = open(vid_path, 'rb')\n",
    "        video_bytes = video_file.read()\n",
    "        st.video(vid_path)\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alJ_yVITv_il"
   },
   "source": [
    "## Streamlit Main App File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHYr9sBpwE4G",
    "outputId": "69063405-ca9e-4c68-ce13-7ea4d25d30a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "from multiapp import MultiApp\n",
    "from apps import home, user, about # import your app modules here\n",
    "\n",
    "app = MultiApp()\n",
    "\n",
    "# Add all your application here\n",
    "app.add_app(\"Home\", home.app)\n",
    "app.add_app(\"User Upload\", user.app)\n",
    "app.add_app(\"About Project\", about.app)\n",
    "# The main app\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MK6ZmvABwI_H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VGG16 Object Detection Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
